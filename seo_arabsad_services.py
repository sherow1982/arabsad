#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø³ÙƒØ±Ø¨Øª Ø³ÙƒÙŠÙ…Ø§ ÙˆSEO Ù„ØµÙØ­Ø§Øª arabsad-ads
Ø±ÙŠØ¨Ùˆ: arabsad-ads (Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨)
Ø§Ù„Ø¨Ù†ÙŠØ©:
- root: Ù…Ù„ÙØ§Øª HTML Ø±Ø¦ÙŠØ³ÙŠØ©
- services/: ØµÙØ­Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª
- cities/: ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø¯Ù†
- blog/: Ø§Ù„Ù…Ø¯ÙˆÙ†Ø©
- blog/articles/: Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
"""

import sys
import re
from pathlib import Path
from datetime import datetime, timedelta

def extract_title(html: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…Ù† <title> Ø£Ùˆ <h1>"""
    m = re.search(r'<title[^>]*>([^<]+)</title>', html, re.IGNORECASE)
    if m:
        txt = m.group(1).strip()
        if '|' in txt:
            txt = txt.split('|')[0].strip()
        return txt if txt else "ØµÙØ­Ø© Ù…Ù† Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨"
    m = re.search(r'<h1[^>]*>([^<]+)</h1>', html, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    return "ØµÙØ­Ø© Ù…Ù† Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨"

def extract_description(html: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØµÙ Ù…Ù† meta Ø£Ùˆ Ø§Ù„Ù†Øµ"""
    m = re.search(r'<meta\s+name=["\']description["\']\s+content=["\']([^"\']+)["\']', html, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    m = re.search(r'<p[^>]*>([^<]+)</p>', html, re.IGNORECASE)
    if m:
        txt = m.group(1).strip()
        if len(txt) > 155:
            txt = txt[:152] + "..."
        return txt
    return "Ø®Ø¯Ù…Ø§Øª ØªØ³ÙˆÙŠÙ‚ Ø±Ù‚Ù…ÙŠ Ù…ØªÙ…ÙŠØ²Ø© Ù…Ù† Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨"

def extract_image(html: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„ØµÙØ­Ø©"""
    m = re.search(r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>', html, re.IGNORECASE)
    if m:
        src = m.group(1).strip()
        if src.startswith('http'):
            return src
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±
        src = src.lstrip('./')
        return f"https://sherow1982.github.io/arabsad-ads/{src}"
    return "https://sherow1982.github.io/arabsad-ads/assets/images/logo.svg"

def determine_page_type(file_path: Path) -> str:
    """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØµÙØ­Ø© (service, city, article, etc)"""
    relative = str(file_path.relative_to(Path("."))).lower()
    
    if 'blog/articles' in relative:
        return 'article'
    elif 'blog' in relative:
        return 'blog'
    elif 'services' in relative:
        return 'service'
    elif 'cities' in relative:
        return 'city'
    else:
        return 'page'

def build_page_url(file_path: Path) -> str:
    """Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· GitHub Pages Ù„Ù„ØµÙØ­Ø©"""
    relative_path = file_path.relative_to(Path("."))
    url_path = str(relative_path).replace("\\", "/")
    return f"https://sherow1982.github.io/arabsad-ads/{url_path}"

def create_service_schema(title: str, image: str, url: str, description: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Service Schema"""
    import json
    schema = {
        "@context": "https://schema.org/",
        "@type": "Service",
        "name": title,
        "image": image,
        "description": description,
        "provider": {
            "@type": "Organization",
            "name": "Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨",
            "url": "https://sherow1982.github.io/arabsad-ads/",
            "logo": "https://sherow1982.github.io/arabsad-ads/assets/images/logo.svg",
            "telephone": "+201110760081"
        },
        "url": url,
        "areaServed": {
            "@type": "Country",
            "name": "Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ"
        },
        "priceRange": "$$-$$$"
    }
    return json.dumps(schema, ensure_ascii=False, indent=2)

def create_article_schema(title: str, image: str, url: str, description: str, file_path: Path) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Article Schema"""
    import json
    try:
        date_modified = datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
    except:
        date_modified = datetime.now().isoformat()
    
    schema = {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": title,
        "image": image,
        "description": description,
        "datePublished": date_modified,
        "dateModified": date_modified,
        "author": {
            "@type": "Organization",
            "name": "Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨"
        },
        "publisher": {
            "@type": "Organization",
            "name": "Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨",
            "logo": {
                "@type": "ImageObject",
                "url": "https://sherow1982.github.io/arabsad-ads/assets/images/logo.svg"
            }
        },
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": url
        },
        "url": url
    }
    return json.dumps(schema, ensure_ascii=False, indent=2)

def create_organization_schema() -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Organization Schema"""
    import json
    schema = {
        "@context": "https://schema.org",
        "@type": "Organization",
        "name": "Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨",
        "alternateName": "ArabSad Digital Marketing",
        "image": "https://sherow1982.github.io/arabsad-ads/assets/images/logo.svg",
        "description": "ÙˆÙƒØ§Ù„Ø© ØªØ³ÙˆÙŠÙ‚ Ø±Ù‚Ù…ÙŠ Ù…ØªØ®ØµØµØ© ÙÙŠ Google Ads ÙˆFacebook Ads ÙˆSEO ÙˆØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹",
        "url": "https://sherow1982.github.io/arabsad-ads/",
        "telephone": "+201110760081",
        "email": "info@arabsad.com",
        "address": {
            "@type": "PostalAddress",
            "addressCountry": "EG",
            "addressRegion": "Ø§Ù„Ø¬ÙŠØ²Ø©",
            "addressLocality": "Ø­Ø¯Ø§Ø¦Ù‚ Ø£ÙƒØªÙˆØ¨Ø±",
            "streetAddress": "Ù…ØµØ±"
        },
        "sameAs": [
            "https://www.facebook.com/arabsad",
            "https://www.twitter.com/arabsad",
            "https://www.instagram.com/arabsad"
        ],
        "contactPoint": {
            "@type": "ContactPoint",
            "contactType": "Customer Support",
            "telephone": "+201110760081",
            "availableLanguage": ["ar"]
        }
    }
    return json.dumps(schema, ensure_ascii=False, indent=2)

def create_local_business_schema() -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ LocalBusiness Schema"""
    import json
    schema = {
        "@context": "https://schema.org",
        "@type": "LocalBusiness",
        "name": "Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨",
        "image": "https://sherow1982.github.io/arabsad-ads/assets/images/logo.svg",
        "url": "https://sherow1982.github.io/arabsad-ads/",
        "telephone": "+201110760081",
        "address": {
            "@type": "PostalAddress",
            "streetAddress": "Ø­Ø¯Ø§Ø¦Ù‚ Ø£ÙƒØªÙˆØ¨Ø±",
            "addressLocality": "Ø§Ù„Ø¬ÙŠØ²Ø©",
            "addressRegion": "Ø§Ù„Ø¬ÙŠØ²Ø©",
            "postalCode": "12572",
            "addressCountry": "EG"
        },
        "geo": {
            "@type": "GeoCoordinates",
            "latitude": "30.0031",
            "longitude": "31.2089"
        },
        "openingHours": "Su-Sa 08:00-23:00",
        "priceRange": "$$"
    }
    return json.dumps(schema, ensure_ascii=False, indent=2)

def create_breadcrumb_schema(file_path: Path) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Breadcrumb Schema"""
    import json
    relative = file_path.relative_to(Path("."))
    parts = relative.parts
    breadcrumb_items = []
    base_url = "https://sherow1982.github.io/arabsad-ads"
    
    breadcrumb_items.append({
        "@type": "ListItem",
        "position": 1,
        "name": "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "item": base_url
    })
    
    current_path = ""
    for i, part in enumerate(parts[:-1], start=2):
        current_path += f"/{part}" if current_path else f"{part}"
        name = part.replace('-', ' ').replace('.html', '').title()
        item_url = f"{base_url}/{current_path}"
        breadcrumb_items.append({
            "@type": "ListItem",
            "position": i,
            "name": name,
            "item": item_url
        })
    
    # Ø¢Ø®Ø± Ø¹Ù†ØµØ± (Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
    current_path += f"/{parts[-1]}" if current_path else parts[-1]
    last_name = parts[-1].replace('-', ' ').replace('.html', '').title()
    breadcrumb_items.append({
        "@type": "ListItem",
        "position": len(parts) + 1,
        "name": last_name,
        "item": f"{base_url}/{current_path}"
    })
    
    schema = {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": breadcrumb_items
    }
    return json.dumps(schema, ensure_ascii=False, indent=2)

def create_meta_tags(title: str, image: str, url: str, description: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Meta + OG + Twitter tags"""
    if len(description) > 155:
        desc_short = description[:152] + "..."
    else:
        desc_short = description
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    title_clean = title.replace('"', '').replace("'", '')
    
    meta = f"""
    <!-- SEO Meta Tags (Auto) -->
    <meta charset="UTF-8">
    <title>{title_clean} - Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨</title>
    <meta name="description" content="{desc_short}">
    <meta name="keywords" content="{title_clean}, ØªØ³ÙˆÙŠÙ‚ Ø±Ù‚Ù…ÙŠ, Google Ads, Facebook Ads, SEO, Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨">
    <meta name="robots" content="index, follow">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="geo.region" content="EG">
    <meta name="geo.placename" content="Ù…ØµØ±">
    <meta name="geo.position" content="30.0031;31.2089">
    <link rel="canonical" href="{url}">
    <!-- Open Graph -->
    <meta property="og:title" content="{title_clean} - Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨">
    <meta property="og:description" content="{desc_short}">
    <meta property="og:image" content="{image}">
    <meta property="og:url" content="{url}">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨">
    <meta property="og:locale" content="ar_EG">
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="{title_clean} - Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨">
    <meta name="twitter:description" content="{desc_short}">
    <meta name="twitter:image" content="{image}">
    """
    return meta

def inject_seo(html: str, title: str, image: str, url: str, description: str, file_path: Path, page_type: str) -> str:
    """Ø­Ù‚Ù† Ø§Ù„Ù…ÙŠØªØ§ ÙˆØ§Ù„Ø³ÙƒÙŠÙ…Ø§ ÙÙŠ <head>"""
    # Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ </head>
    if '</head>' not in html:
        if '<body' in html.lower():
            html = html.replace('<body', '</head><body', 1)
        else:
            html = html + '</head>'
    
    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø³ÙƒÙŠÙ…Ø§ JSON-LD Ù‚Ø¯ÙŠÙ…
    html = re.sub(
        r'<script\s+type=["\']?application/ld\+json["\']?\s*>.*?</script>',
        '',
        html,
        flags=re.DOTALL | re.IGNORECASE
    )
    
    meta = create_meta_tags(title, image, url, description)
    org_schema = create_organization_schema()
    local_schema = create_local_business_schema()
    breadcrumb_schema = create_breadcrumb_schema(file_path)
    
    # Schema Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ØµÙØ­Ø©
    if page_type == 'article':
        main_schema = create_article_schema(title, image, url, description, file_path)
        schema_type = "<!-- Article Schema JSON-LD (Auto) -->"
    else:
        main_schema = create_service_schema(title, image, url, description)
        schema_type = "<!-- Service Schema JSON-LD (Auto) -->"
    
    injection = f"""
{meta}

{schema_type}
<script type="application/ld+json">
{main_schema}
</script>

<!-- Organization Schema JSON-LD (Auto) -->
<script type="application/ld+json">
{org_schema}
</script>

<!-- LocalBusiness Schema JSON-LD (Auto) -->
<script type="application/ld+json">
{local_schema}
</script>

<!-- Breadcrumb Schema JSON-LD (Auto) -->
<script type="application/ld+json">
{breadcrumb_schema}
</script>

</head>"""
    
    return html.replace('</head>', injection, 1)

def process_file(file_path: Path) -> tuple:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù HTML ÙˆØ§Ø­Ø¯"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            html = f.read()
        
        title = extract_title(html)
        image = extract_image(html)
        description = extract_description(html)
        url = build_page_url(file_path)
        page_type = determine_page_type(file_path)
        
        updated = inject_seo(html, title, image, url, description, file_path, page_type)
        
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(updated)
        
        return (True, file_path.relative_to(Path(".")), page_type)
    except Exception as e:
        return (False, file_path.relative_to(Path(".")), str(e))

def main():
    print("\n" + "="*70)
    print("ğŸ† Ø³ÙƒØ±Ø¨Øª SEO + Ø³ÙƒÙŠÙ…Ø§ Ù„Ù…Ø¤Ø³Ø³Ø© Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ ğŸ†")
    print("="*70 + "\n")

    root = Path(".")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª HTML ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª
    search_paths = [
        ("root", root, "*.html"),
        ("services", root / "services", "*.html"),
        ("cities", root / "cities", "*.html"),
        ("blog", root / "blog", "*.html"),
        ("articles", root / "blog" / "articles", "*.html"),
    ]
    
    all_files = []
    for folder_name, folder_path, pattern in search_paths:
        if folder_path.exists():
            files = sorted(folder_path.glob(pattern))
            all_files.extend(files)
            if files:
                print(f"ğŸ“‚ {folder_name}: {len(files)} Ù…Ù„Ù")
    
    if not all_files:
        print("\nâŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª HTML ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
        sys.exit(1)

    print(f"\nğŸ“¦ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {len(all_files)}\n")
    print("-" * 70 + "\n")

    ok = 0
    fail = 0
    stats = {"service": 0, "article": 0, "city": 0, "blog": 0, "page": 0}

    for i, fp in enumerate(all_files, 1):
        rel_path = fp.relative_to(root)
        print(f"[{i}/{len(all_files)}] {rel_path} ...", end=" ")
        
        success, filename, result = process_file(fp)
        if success:
            page_type = result
            stats[page_type] = stats.get(page_type, 0) + 1
            print(f"âœ… ({page_type})")
            ok += 1
        else:
            print(f"âŒ {result}")
            fail += 1

    print("\n" + "="*70)
    print("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print("="*70)
    print(f"âœ… Ù†Ø¬Ø­: {ok} Ù…Ù„Ù")
    print(f"âŒ ÙØ´Ù„: {fail} Ù…Ù„Ù")
    print(f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(ok/len(all_files)*100):.1f}%")
    print("\nğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹:")
    for page_type, count in stats.items():
        if count > 0:
            print(f"   â€¢ {page_type}: {count} Ù…Ù„Ù")
    print("="*70)
    print("\nâœ¨ ØªÙ… Ø¥Ø¶Ø§ÙØ© Schema ÙˆÙ…Ø­Ø³Ù†Ø§Øª SEO Ù„ÙƒÙ„ Ø§Ù„ØµÙØ­Ø§Øª!\n")

if __name__ == "__main__":
    main()
